\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{float}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{titlesec}
\renewcommand{\thesubsubsection}{\alph{subsubsection}.}
\titleformat{\subsubsection}[runin]
  {\normalfont\normalsize\bfseries}
  {\thesubsubsection}
  {1em}
  {}
  [\newline]
\setcounter{secnumdepth}{3}
\usepackage{enumitem}
\usepackage{stfloats}
    
\begin{document}

\title{
  Localization using poles \& signs detected by a lidar 
  \\
  \large UTC - ARS4 - Estimation for robotic navigation
}

\author{Victor Demessance, Galia Fabiola Cornejo Urquieta, Fadi Ben Ali}

\maketitle

\section{System modeling}

\vspace{2mm}

\subsection{State vector}

\noindent In order to represent the pose of the vehicule in the 2D space, we can use the following state vector \( \mathbf{x}_t \) :
\[
X = 
\begin{bmatrix}
x \\ 
y \\ 
\theta \\ 
v \\ 
\omega
\end{bmatrix}
\]
with :
\begin{itemize}
    \item \( x, y \) : Coordinates of the vehicule (ENU working frame).
    \item \( \theta \) : Heading of the vehicule (ENU working frame).
    \item \( v \) : Longitudinal speed.
    \item \( \omega \) : Angular speed.
\end{itemize}

\subsection{Dynamic space state model}

\noindent The evolution of the system can be define as follows :
\[
X_{t+1} = f(X_t, u_t) + q_t
\]
with :
\begin{itemize}
    \item $\mathbf{u}_t = [v_t, \omega_t]^T$ : speed inputs.
    \item $\mathbf{q}_t \sim \mathcal{N}(0, Q)$ : model noise.
\end{itemize}

\vspace{2mm}

\noindent Thanks to the Euler method, that uses the derivatives definition to define the value of the next iteration of the discrete space state, we have : 
\[
X_{k+1} = X(t) + \Delta.\dot{X}(t),
\]
\noindent Using basic definitions of geometry and automatic control, we can define the nonlinear function f such that (assuming constant speeds between 2 samples) : 
\[
\begin{aligned}
x_{t+1} &= x_t + v_t \Delta t \cos(\theta_t), \\
y_{t+1} &= y_t + v_t \Delta t \sin(\theta_t), \\
\theta_{t+1} &= \theta_t + \omega_t \Delta t, \\
v_{t+1} &= v_t, \\
\omega_{t+1} &= \omega_t.
\end{aligned}
\]

\noindent Consequently, we have 

\begin{align*}
    f(X_t, u_t) =
    \begin{bmatrix}
    x_t + v_t \Delta t \cos(\theta_t), \\
    y_t + v_t \Delta t \sin(\theta_t), \\
    \theta_t + \omega_t \Delta t, \\
    v_t, \\
    \omega_t.
    \end{bmatrix}.
\end{align*}


\newpage

\section{Observation Model}

\noindent We can define observation as the reception of GNSS and Lidar information. In the model, we describe it as :

\vspace{2mm}
\begin{itemize}
    \item GNSS ($x_{GNSS}$, $y_{GNSS}$, $\theta_{GNSS}$)
    \begin{align*}
        x_\text{GNSS} &= x \\
        y_\text{GNSS} &= y \\
        \theta_\text{GNSS} &= \theta
    \end{align*}
    with $\sigma_{x}^{2} = \sigma_{y}^{2} = 0.2$ and $\sigma_{\theta}^{2} = 0.01$ 
    
    \vspace{4mm}

    \item Lidar ($x_{lidar}$, $y_{lidar}$, $x_{map}$, $y_{map}$)
   
    \vspace{2mm}
    
    To process LiDAR observation, we make a change of variables in polar coordinates to compute the estimated observation:

    \begin{equation*}
        \hat{\rho}^{i} = \sqrt{(x_{map}^{i} - x_t)^2 + (y_{map}^{i} - y_t)^2} 
    \end{equation*}
    \begin{equation*}
        \hat{\lambda}^{i} = \arctan2(y_{map}^{i} - y_t, x_{map}^{i} - x_t) - \theta_t
    \end{equation*}

    \noindent And so we can compare it with the real observation in polar coordinates
    \begin{equation*}
        \rho^{i} = \sqrt{(x_{lidar})^2 + (y_{lidar})^2} 
    \end{equation*}
    \begin{equation*}
        \lambda^{i} = \arctan2(y_{lidar}, x_{lidar})
    \end{equation*}
\end{itemize}

\vspace{2mm}

\noindent The global observation model equation can be finally written as follows (defining $M$ as the map informations):

\[
\mathbf{z}_t = g(X_t, M),
\]

with
\[
\mathbf{z}_t =
\begin{bmatrix}
x_\text{GNSS} \\
y_\text{GNSS} \\
\theta_\text{GNSS} \\
\rho^{i} \\
\lambda^{i}
\end{bmatrix}, \quad
g(X_t, M) =
\begin{bmatrix}
g_\text{GNSS} \\
g_\text{LiDAR}
\end{bmatrix} = 
\begin{bmatrix}
x_t \\
y_t \\
\theta_t \\
\hat{\rho}^{i} \\
\hat{\lambda}^{i} \\
\end{bmatrix}.
\]

\vspace{3mm}

\noindent As Lidar obervations are received at a higher frequency than GNSS observations (10Hz vs. 1Hz), they will enable us to update our state estimation more frequently.

\section{Simulation Implementation}

\subsection{Extended Kalman Filter}

Filter is implemented following system and observation modelling sections. Once implemented, we seek to tune it so that it has 95\% consistency. We also have to check if the estimation error is not biased. We do consistency test using the reference values for the variables x, y and heading (h). We do the test for each of them. The results are shown in the following table:

\begin{align*}
\begin{tabular}{c|c|c|c|c} 
  Variable & Mean Error & Max Error & MSE & Consistency \\ \hline 
  x & 0.10644 & 1.9729 & 0.15641 & 0.99853 \\
  y   & -0.056811 & 2.3455 &  0.12408 & 0.98387\\
\end{tabular}
\end{align*}


The initial state for the simulation refered to the first position of the GNSS sensor. We have \begin{align*}
   x_0 = \begin{bmatrix}
    \text{gnss(1).x} \\ 
    \text{gnss(1).y} \\
    \text{gnss(1).heading} \\
    \text{v(1)} \\
    \text{omega(1)}
    \end{bmatrix}
\end{align*}

\noindent Initial covariance matrix $P$ is set to
\begin{align*}
   P = \begin{bmatrix}
    0.1 & 0 & 0 & 0 & 0 \\ 
    0 & 0.1 & 0 & 0 & 0 \\
    0 & 0 & 0.1 & 0 & 0 \\
    0 & 0 & 0 & 0.5 & 0 \\
    0 & 0 & 0 & 0 & 0.5
    \end{bmatrix}
\end{align*}

\noindent Initial process noise matrix $Q$ is set to
\begin{align*}
   Q = \begin{bmatrix}
    0.1 & 0 & 0 & 0 & 0 \\ 
    0 & 0.1 & 0 & 0 & 0 \\
    0 & 0 & 0.7 & 0 & 0 \\
    0 & 0 & 0 & 0.1 & 0 \\
    0 & 0 & 0 & 0 & 0.5
    \end{bmatrix}
\end{align*}

\begin{align*}
   R_g = \begin{bmatrix}
    0.1 & 0 & 0 \\ 
    0 & 0.1 & 0 \\
    0 & 0 & 0.01  \\
    \end{bmatrix}
\end{align*}


\begin{align*}
   R_l = \begin{bmatrix}
    0.7 & 0 \\ 
    0 & 0.7 \\
    \end{bmatrix}
\end{align*}

\noindent Note that we trust a lot more the GNSS measures than the lidar measures, given the fact that in real data, detection algorithms may fall to detect poles and traffic signs and may also detect some false positives, so we expect to have a really noisy data.

\noindent For the simulation, we decided to separate the two observation models and implement 2 separate Kalman filters. In this way, we can correct the state with two types of independent observations.

To apply EKF, we need to compute the jacobians of the observation and evolution models. We have :
\begin{align*}
    F &= \frac{\partial f}{\partial X} \\ 
    &=
    \begin{bmatrix}
    1 & 0 & -v \Delta t \sin(\theta) & \Delta t \cos(\theta) & 0 \\
    0 & 1 & v \Delta t \cos(\theta) & \Delta t \sin(\theta) & 0 \\
    0 & 0 & 1 & 0 & \Delta t \\
    0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1
    \end{bmatrix}.
\end{align*}

\begin{align*}
    C_{\text{GNSS}} &= \frac{\partial g_\text{GNSS}}{\partial X} =
    \begin{bmatrix}
    1 & 0 & 0 & 0 & 0\\
    0 & 1 & 0 & 0 & 0\\
    0 & 0 & 1 & 0 & 0\\
    \end{bmatrix}.
\end{align*}

\[
C_{\text{LiDAR}} =
\begin{bmatrix}
-\frac{\Delta X}{r} & -\frac{\Delta Y}{r} & 0 & 0 & 0 \\
\frac{\Delta Y}{r^2} & -\frac{\Delta X}{r^2} & -1 & 0 & 0 \\
\end{bmatrix}
\]

With 
\begin{align*}
    \Delta_X &= x_{map} - x_t \\ 
    \Delta_Y &= y_{map} - y_t \\ 
    r &= \sqrt{\Delta_X^2 + \Delta_Y^2}
\end{align*}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{simulation_GNSS_trajectory.png}
    \caption{EKF Localization with GNSS and LiDAR observations}
    \label{fig:enter-label}
\end{figure}

\subsection{Unscented Kalman Filter}

Following the same protocole we have the following results for the unscented kalman filter:

\begin{align*}
\begin{tabular}{c|c|c|c|c} 
  Variable & Mean Error & Max Error & MSE & Consistency \\ \hline 
  x & -0.03998 & 0.51297 & 0.028646 & 1.0000 \\
  y & -0.16454 & 0.61987 &  0.055269 & 0.99413\\
  h & -0.0082228 & 0.042492 &  0.00010691 & 1.0000\\
\end{tabular}
\end{align*}


The initial state for the simulation refered to the first position of the GNSS sensor. We have \begin{align*}
   x_0 = \begin{bmatrix}
    \text{gnss(1).x} \\ 
    \text{gnss(1).y} \\
    \text{gnss(1).heading} \\
    \text{v(1)} \\
    \text{omega(1)}
    \end{bmatrix}
\end{align*}

\noindent Initial covariance matrix $P$ is set to
\begin{align*}
   P = \begin{bmatrix}
    0.5 & 0 & 0 & 0 & 0 \\ 
    0 & 0.5 & 0 & 0 & 0 \\
    0 & 0 & 0.1 & 0 & 0 \\
    0 & 0 & 0 & 0.5 & 0 \\
    0 & 0 & 0 & 0 & 0.5
    \end{bmatrix}
\end{align*}

\noindent Initial process noise matrix $Q$ is set to
\begin{align*}
   Q = \begin{bmatrix}
    0.1 & 0 & 0 & 0 & 0 \\ 
    0 & 0.1 & 0 & 0 & 0 \\
    0 & 0 & 0.001 & 0 & 0 \\
    0 & 0 & 0 & 0.1 & 0 \\
    0 & 0 & 0 & 0 & 0.001
    \end{bmatrix}
\end{align*}

\begin{align*}
   R_g = \begin{bmatrix}
    0.2 & 0 & 0 \\ 
    0 & 0.2 & 0 \\
    0 & 0 & 0.01  \\
    \end{bmatrix}
\end{align*}


\begin{align*}
   R_l = \begin{bmatrix}
    0.3 & 0 \\ 
    0 & 0.3 \\
    \end{bmatrix}
\end{align*}

\noindent Note that we trust more the GNSS measures than the lidar measures, just as the previous case.

\vspace{2mm}

\noindent In order to set up the UKF filter, we need to define our sigma points. In our case, th such that : 

 \[
    \mathbf{X}_i = x \pm \sqrt{(n + \lambda)\mathbf{P}}, \quad i = 1, \dots, 2n
 \]

with 
\begin{itemize}
    \item $\lambda = \alpha^2(n + \kappa) - n$
    \item $n$ the state vector dimension
    \item $\alpha, \beta, \kappa$ \text{parameters defining the spread of sigma points}
\end{itemize}

\vspace{2mm}

\noindent Then, we propagate sigma points $\mathbf{X}_i$ through the dynamic model:
    \[
    \mathbf{X}_i^{\text{pred}} = f(\mathbf{X}_i, u_t)
    \]
\noindent and we can compute the statistical moments of the model like in the UKF definition. The rest is simply the application of the UKF filter's discounting and prediction formulas. You can see the results on the Figure n°2.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{UKF_results.png}
    \caption{UKF Localization with GNSS and LiDAR observations}
    \label{fig:enter-label}
\end{figure}

\vspace{3mm}

\section{Real Implementation}

\vspace{2mm}

\subsection{Multi sensor data fusion}

To be able to use the LiDAR observations in real time, we need to create a data association algorithm that will link the observation to the global pole position in the ENU frame. We create a NN association based on the global poles map (Figure n°3) and the observed poles converted in the ENU frame.   

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{globalMapPoles_trajectory.png}
    \caption{Global Poles Map superposed on the Reference Trajectory (with GNSS obs)}
    \label{fig:enter-label}
\end{figure}

For each pole detected by the LiDAR, its coordinates in the vehicle frame \((x_{\text{lidar}}, y_{\text{lidar}})\) are transformed into the global frame \((x_{\text{lidar}}^{M}, y_{\text{lidar}}^{M})\) using the current estimated robot state \((x_t, y_t, \theta_t)\). For this process, we use the \textbf{cartesian coordinates} and we compute :

\[
\begin{bmatrix}
x_{\text{lidar}}^{M} \\
y_{\text{lidar}}^{M}
\end{bmatrix}
=
\begin{bmatrix}
x_t \\
y_t
\end{bmatrix} 
+
R(\theta_t)
\begin{bmatrix}
x_{\text{lidar}} \\
y_{\text{lidar}}
\end{bmatrix}
\]
\noindent That can be reformulate as :

\[
x_{\text{lidar}}^{M} = x_t + \cos(\theta_t) \cdot x_{\text{lidar}} - \sin(\theta_t) \cdot y_{\text{lidar}}
\]
\[
y_{\text{lidar}}^{M} = y_t + \sin(\theta_t) \cdot x_{\text{lidar}} + \cos(\theta_t) \cdot y_{\text{lidar}}
\]

\noindent After that, we compute the Euclidean distance between its position \((x_{\text{lidar}}^{M}, y_{\text{lidar}}^{M})\) and all the poles in the map \((x_{\text{map}}, y_{\text{map}})\)
\[
\text{d}_{j} = \sqrt{(x_{\text{map}}^j - x_{\text{lidar}}^{M})^2 + (y_{\text{map}}^j - y_{\text{lidar}}^{M})^2}
\]
where \(j\) iterates over all the poles in the map.

\vspace{2mm}

\noindent In the case of a NN association, we basically link the map pole with the smallest distance to the detected pole as the corresponding association (Figure n°4):
\[
j^* = \arg\min_j \text{d}_j
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{NN_association_trajectory.png}
    \caption{NN process on LiDAR observation with selected linked map poles}
    \label{fig:enter-label}
\end{figure}


\subsection{Extended Kalman Filter}

The implementation of the EKF is the same than in the simulation part, we just need to apply the NN algorithm before the process of LiDAR observation.

\subsection{Unscented Kalman Filter}

Development of the UKF filter for real data is carried out in the same way as for simulated data, using the nearest neighbor data association process accordingly.

\vspace{3mm}

\newpage

\section{Filter comparison}

To evaluate the two filters we use reference values and compute for variables x, y and h. 

\noindent Unfortunately, we didn't have time to finalize the development of the UKF filter for real data. As a result, the comparison table is only available for simulated data.

\begin{table}[H]
\centering
\caption{Filter comparison}
\begin{tabular}{c|c|c|c|c|c|c} 
\multicolumn{7}{|c|}{\textbf{SIMULATION}}\\ \hline
 & \multicolumn{2}{|c|}{\textbf{Mean Error}} & \multicolumn{2}{|c|}{\textbf{Max Error}} & \multicolumn{2}{|c|}{\textbf{MSE}}\\ \hline
var & EKF & UKF & EKF & UKF & EKF & UKF \\ \hline
  x  & 0.10644 & -0.03998 & 1.9729 & 0.51297 & 0.15641 & 0.028646\\
  y   & -0.056811 & -0.16454 &  2.3455 & 0.61987 & 0.12408 & 0.055269 \\
  h   & -1.2708 & -0.0082228 &  6.3689 & 0.042492 & 2.567 & 0.00010691 \\
\end{tabular}

\end{table}

\vspace{3mm}

\section{Conclusions}

According to the results in the previous table, we can see that the UKF filter works better than the EKF. Particularly, the estimate of the variable h made by the unscented Kalman filter is impressive compared to the estimate made by the filter. This is something we expected, since the filter propagates the sigma points through the non-linear functions and therefore does not make linear approximations.

We conclude also that, in general, for the initial values, we assume that the lidar data is less reliable than the gnss and therefore it has more noise (in fact, for the real data, the lidar may miss some poles or detect some false positives).

\end{document}

